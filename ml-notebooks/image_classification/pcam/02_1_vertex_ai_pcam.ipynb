{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "673e8a116c04"
   },
   "source": [
    "# Using Vertex AI to train an image classification model\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Run the <a href=\"xxx\"><code>00_pcam_setup.ipynb notebook</code></a> first, before running this one.  You'll need the settings info from that notebook.\n",
    "</div>\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook shows some examples of how to use [Vertex AI](https://cloud.google.com/vertex-ai/docs) for training a machine learning model. \n",
    "\n",
    "It shows how to define and submit a **model training job**; then how to upload and deploy that model for serving; and then how to send prediction requests to the deployed model's *Endpoint*. It also shows how to create and use a Managed Tensorboard instance during training, and how to log information about the training run to the Vertex Experiments API.\n",
    "\n",
    "Then, a follow-on notebook, `02_2_vertex_ai_pcam`, shows how to set up a [**hyperparameter tuning**](https://en.wikipedia.org/wiki/Hyperparameter_optimization) job using that same model; and how to set up and run a **distributed multi-node training** job.\n",
    "\n",
    "Then, a following set of notebooks show how to use Vertex Pipelines to define ML workflows for data preprocessing, training, model evaluation, and deployment.\n",
    "\n",
    "Currently, the code is on GitHub here: https://github.com/verily-src/terra-solutions-ml.\n",
    "\n",
    "### Estimated cost of running this notebook\n",
    "\n",
    "The dataset used for the examples in this notebook is fairly large, as is the base model architecture, and training using the notebook's default configurations will take about 1.5 hours.\n",
    "\n",
    "The model training works best with GPU(s)— it runs fine using only CPUs, but training will take an even longer time. For this example, the notebook itself doesn't need GPUs; instead they'll be used by Vertex AI.\n",
    "\n",
    "This example should cost < $2 in Vertex AI charges to run (billed to your ['native' GCP project](https://support.terra.bio/hc/en-us/articles/360051229072-Accessing-advanced-GCP-features-in-Terra)), not including the cost of the notebook instance.\n",
    "\n",
    "### Running on a [Terra](http://app.terra.bio) notebook\n",
    "\n",
    "This example requires that TensorFlow >= 2.6 be installed, and does not require GPUs; instead the example uses GPUs on Vertex AI Training.\n",
    "You can use the default GATK image. \n",
    "\n",
    "You will need to use a ['native' GCP project](https://support.terra.bio/hc/en-us/articles/360051229072-Accessing-advanced-GCP-features-in-Terra) to connect to the Vertex AI services.  The `00_pcam_setup.ipynb` notebook, which should be run before this one, will walk you through that setup.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "This notebook is not designed for running all the cells at once via a 'Run All'— rather, you will need to wait until training has finished to run the latter parts of the example.\n",
    "    \n",
    "If you like, you can shut down the notebook instance/Cloud Environment while the training job runs— monitoring its progress in the Cloud Console UI— and then restart the notebook instance when the job is finished to complete the example. If you do this, you'll need to do a bit of additional work to redefine some imports and config after the notebook is restarted.  \n",
    "</div>\n",
    "\n",
    "To monitor the logs for a training job while it is running, click on the links output to the notebook when you start the training job.  You can also visit the [Vertex AI tab in the Cloud Console](https://console.cloud.google.com/vertex-ai/training/custom-jobs) for your 'native' GCP project, and click on 'Training', then 'CUSTOM JOBS'.  From that list of jobs, click in to any of them— look for your username— then click on the 'Logs' link in the detailed view.\n",
    "<img src=\"https://storage.googleapis.com/amy-jo/images/terra/CleanShot%202022-02-18%20at%2013.48.34%402x.png\" width=\"90%\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64d08d22a9e3"
   },
   "source": [
    "### About the ML task and dataset\n",
    "\n",
    "This notebook shows an example of training an _image classification_ [Keras](https://keras.io/) model.\n",
    "\n",
    "The [PatchCamelyon benchmark](https://www.tensorflow.org/datasets/catalog/patch_camelyon) consists of 327,680 color images (96 x 96px) extracted from histopathologic scans of lymph node sections. Each image is annotated with a\n",
    "binary label indicating presence of metastatic tissue. \n",
    "\n",
    "The model uses one of Keras' prebuilt model architectures, [Xception](https://keras.io/api/applications/xception/). The training does [_transfer learning_](https://en.wikipedia.org/wiki/Transfer_learning) , bootstrapping from model weights trained on the ['imagenet'](https://en.wikipedia.org/wiki/ImageNet) dataset.\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/tfds-data/visualization/fig/patch_camelyon-2.0.0.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "af1424701a34"
   },
   "source": [
    "## Config and setup\n",
    "\n",
    "We'll first do some configuration and set some variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "918da3c9304d"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import IPython\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform import gapic as aip\n",
    "from PIL import Image\n",
    "\n",
    "IMAGE_HEIGHT = 96\n",
    "IMAGE_WIDTH = 96\n",
    "\n",
    "IMAGE_SIZE = (IMAGE_HEIGHT, IMAGE_WIDTH)\n",
    "\n",
    "LABELS = [\"non_metastatic\", \"metastatic\"]\n",
    "BATCH_SIZE = 32\n",
    "NB_NUM = \"02-1\"\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3dda6783e1f"
   },
   "source": [
    "We'll set some variables using Workspace Data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d705ee03362a"
   },
   "outputs": [],
   "source": [
    "OWNER_EMAIL = \"\"\n",
    "USER = \"\"\n",
    "\n",
    "if (\n",
    "    \"GOOGLE_PROJECT\" in os.environ\n",
    "):  # This env var is set when running in a Terra workspace\n",
    "    from firecloud import api as fapi\n",
    "\n",
    "    WORKSPACE_NAME = os.environ[\"WORKSPACE_NAME\"]\n",
    "    WORKSPACE_NAMESPACE = os.environ[\"WORKSPACE_NAMESPACE\"]\n",
    "    OWNER_EMAIL = os.environ[\"OWNER_EMAIL\"]\n",
    "    # WORKSPACE_ATTRIBUTES contains key-value pairs from the \"Workspace Data\" section of the Workspace \"Data\" tab.\n",
    "    WORKSPACE_ATTRIBUTES = (\n",
    "        fapi.get_workspace(WORKSPACE_NAMESPACE, WORKSPACE_NAME)\n",
    "        .json()\n",
    "        .get(\"workspace\", {})\n",
    "        .get(\"attributes\", {})\n",
    "    )\n",
    "\n",
    "    # set a variable from the workspace attributes\n",
    "    PYTHON_PACKAGE_GCS_URI_WS = WORKSPACE_ATTRIBUTES[\"PYTHON_PACKAGE_GCS_URI_WS\"]\n",
    "    print(f\"PYTHON_PACKAGE_GCS_URI_WS: {PYTHON_PACKAGE_GCS_URI_WS}\")\n",
    "else:\n",
    "    print(\n",
    "        \"Not running on Terra: you will need to set some variables manually. See below.\"\n",
    "    )\n",
    "\n",
    "if OWNER_EMAIL:\n",
    "    USER = OWNER_EMAIL.split(\"@\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set some variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Edit the cell below before running it**.  **Replace the values with the ones for your 'native' GCP project** generated when running the `00_pcam_setup.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7636e20d86eb"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"your-project-id\"\n",
    "# The service account you've set up for these Vertex AI examples\n",
    "TRAINING_SA = \"your-sa-name@your-project-id.iam.gserviceaccount.com\"\n",
    "BUCKET_NAME = (\n",
    "    \"your-bucket-name\"  # don't include the 'gs://' prefix; that is added below\n",
    ")\n",
    "# The TensorBoard instance you created: optional but useful\n",
    "TENSORBOARD_INSTANCE = (\n",
    "    \"projects/xxxxxxxxxxxx/locations/us-central1/tensorboards/xxxxxxxxxxxxxxxxxxx\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ae298449f2ef"
   },
   "source": [
    "The `USER` value will be used to create Vertex resource and job names, so that you can locate your info more easily in the GCP Cloud Console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "926b6df936e2"
   },
   "outputs": [],
   "source": [
    "if USER == \"\" or USER is None:\n",
    "    USER = \"your-username\"  # <-- CHANGE THIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44da8bbd7258"
   },
   "source": [
    "Make sure `USER` was set correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ac6fe645f23"
   },
   "outputs": [],
   "source": [
    "print(f\"USER: {USER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d598bcdd2f4e"
   },
   "outputs": [],
   "source": [
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52e9ea8b0943"
   },
   "source": [
    "### Ensure that the PROJECT_ID is set correctly and set your region\n",
    "\n",
    "Ensure that your project ID has been set correctly. This should be the project ID of the ['native' GCP project](https://support.terra.bio/hc/en-us/articles/360051229072-Accessing-advanced-GCP-features-in-Terra).  (This is different from the project for your workspace)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2554b2b199b1"
   },
   "outputs": [],
   "source": [
    "print(PROJECT_ID)\n",
    "LOCATION = \"us-central1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9923bc2d3058"
   },
   "source": [
    "### Check the service account used for some of the Vertex AI calls\n",
    "\n",
    "You'll use the service account that you set up in your native GCP project. Ensure that it's set properly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "08e86c7a9fbf"
   },
   "outputs": [],
   "source": [
    "TRAINING_SA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37d5e1007997"
   },
   "source": [
    "### Set a Cloud Storage bucket to use for this example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ee3df410af6b"
   },
   "outputs": [],
   "source": [
    "BUCKET = f\"gs://{BUCKET_NAME}\"\n",
    "print(BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the Python package with the training code to your bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PYTHON_PACKAGE_GCS_URI = BUCKET + \"/pcam/dist/trainer-0.7.tar.gz\"\n",
    "print(PYTHON_PACKAGE_GCS_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp $PYTHON_PACKAGE_GCS_URI_WS $PYTHON_PACKAGE_GCS_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls $PYTHON_PACKAGE_GCS_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a5d1293a02c6"
   },
   "source": [
    "### Initialize the Vertex AI SDK with your project, location, and bucket settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f6b35f4e8bb4"
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=LOCATION, staging_bucket=BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4efcaed70f5c"
   },
   "source": [
    "## Optional: Create an Experiment for tracking training related metadata\n",
    "\n",
    "The Vertex AI Experiments API is useful for tracking information about your training runs.  You can retrieve the logged information via a pandas dataframe for analysis and comparison.\n",
    "\n",
    "We'll start by creating an `Experiment`.  Then, in the following sections, we'll define Experiment `runs` and log information about the training jobs to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d5e3b8885b3c"
   },
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = f\"{USER}-pcam-{NB_NUM}-{TIMESTAMP}\"\n",
    "print(f\"experiment name: {EXPERIMENT_NAME}\")\n",
    "aiplatform.init(experiment=EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cb9102b290fd"
   },
   "source": [
    "## Train the model on Vertex AI using the Vertex AI SDK\n",
    "\n",
    "Now we'll define the training code that we'll run on Vertex AI.  You can indicate the filepath to a Python script when defining the training job, or alternately package your code as a module, upload it to GCS, and indicate that URL instead.  We'll show examples of both below.\n",
    "\n",
    "Using the defaults, this training job will take about 2.5 hours to run. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10b144e5321b"
   },
   "source": [
    "### Define a training script\n",
    "\n",
    "This script is a simplified version of the package checked in to GitHub [here](https://github.com/DataBiosphere/terra-example-notebooks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e21ceacc79d1"
   },
   "outputs": [],
   "source": [
    "%%writefile pcamtask.py\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import hypertune\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "\n",
    "LABELS = ['non_metastatic', 'metastatic']\n",
    "\n",
    "\n",
    "def generate_camelyon_datasets(batch_size):\n",
    "  ds, ds_info = tfds.load('patch_camelyon', with_info = True, as_supervised = True)\n",
    "\n",
    "  #Get the train, validation and test datasets\n",
    "  training_data = ds['train']\n",
    "  validation_data = ds['validation']\n",
    "  test_data = ds['test']\n",
    "\n",
    "  # shuffle train_data\n",
    "  buffer_size = 1000\n",
    "  training_data = training_data.shuffle(buffer_size)\n",
    "\n",
    "  # batch and prefetch\n",
    "  training_data = training_data.batch(batch_size).prefetch(1)\n",
    "  validation_data = validation_data.batch(batch_size).prefetch(1)\n",
    "  test_data = test_data.batch(batch_size).prefetch(1)\n",
    "\n",
    "  return(training_data, validation_data, test_data, ds_info)\n",
    "\n",
    "\n",
    "def get_compiled_model(lr, image_height, image_width):\n",
    "  base_model = keras.applications.Xception(\n",
    "      weights=\"imagenet\",\n",
    "      input_shape=(image_height, image_width, 3),\n",
    "      include_top=False,\n",
    "  )\n",
    "\n",
    "  base_model.trainable = False\n",
    "\n",
    "  inputs = keras.Input(shape=(image_height, image_width, 3))\n",
    "\n",
    "  x = layers.Rescaling(1.0 / 255)(inputs)\n",
    "  x = base_model(x, training=False)\n",
    "  x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "  # x = keras.layers.Dropout(0.2)(x)\n",
    "  outputs = keras.layers.Dense(len(LABELS), activation=\"softmax\")(x)\n",
    "\n",
    "  model = keras.Model(inputs, outputs)\n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "  model.compile(\n",
    "      optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "      loss=loss,\n",
    "      metrics=[\"accuracy\"],\n",
    "  )\n",
    "  return model\n",
    "\n",
    "\n",
    "def define_callbacks(log_dir, checkpoint_dir):\n",
    "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "      log_dir=log_dir, update_freq=300\n",
    "  )\n",
    "  model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "      filepath=checkpoint_dir,\n",
    "      #     save_weights_only=True,\n",
    "      monitor=\"val_accuracy\",\n",
    "      mode=\"max\",\n",
    "      save_freq=\"epoch\"\n",
    "      #     save_best_only=True\n",
    "  )\n",
    "  return (tensorboard_callback, model_checkpoint_callback)\n",
    "\n",
    "\n",
    "def generate_metrics(validation_set, model):\n",
    "  ma = tf.keras.metrics.AUC()\n",
    "  mp = tf.keras.metrics.Precision()\n",
    "  mr = tf.keras.metrics.Recall()\n",
    "\n",
    "  all_preds = []\n",
    "  all_labels = []\n",
    "\n",
    "  for images, labels in validation_set.take(len(validation_set)):\n",
    "    predictions = model.predict(images)\n",
    "    y_preds = np.argsort(predictions, axis=1)[:, -1:]\n",
    "\n",
    "    all_preds += list(y_preds.flatten())\n",
    "    all_labels += list(labels.numpy())\n",
    "    onehot_labels = tf.keras.utils.to_categorical(\n",
    "        labels, num_classes=len(LABELS)\n",
    "    )\n",
    "    ma.update_state(onehot_labels, predictions)\n",
    "    mp.update_state(onehot_labels, predictions)\n",
    "    mr.update_state(onehot_labels, predictions)\n",
    "  return (ma, mp, mr, all_preds, all_labels)\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "  logging.getLogger().setLevel(logging.INFO)\n",
    "  parser = argparse.ArgumentParser(description=\"ML Trainer\")\n",
    "  parser.add_argument(\"--epochs\", type=int, default=4)\n",
    "  parser.add_argument(\"--batch-size\", type=int, default=32)\n",
    "  parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
    "  parser.add_argument(\"--image-height\", type=int, default=96)\n",
    "  parser.add_argument(\"--image-width\", type=int, default=96)\n",
    "\n",
    "  parser.add_argument(\"--gcs-workdir\", required=True)\n",
    "  parser.add_argument(\"--gcs-model-savedir\", required=True)\n",
    "  parser.add_argument(\"--gcs-metrics-path\", required=True)\n",
    "  # required for consistency with the training package args\n",
    "  parser.add_argument(\"--ml-task\", default='patchcamelyon')\n",
    "    \n",
    "\n",
    "  parser.add_argument(\n",
    "      \"--input-data-dir\",\n",
    "      default='/gcs/terra-solutions-ml-exs-debug/data/model_data/training_data/',\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      \"--input-data\",\n",
    "      default=\"gs://terra-solutions-ml-exs-debug/data/model_data.zip\",\n",
    "  )\n",
    "  parser.add_argument(\"--copy-data\", default=False, action=\"store_true\")\n",
    "  parser.add_argument(\"--use-fuse\", dest=\"copy-data\", action=\"store_false\")\n",
    "\n",
    "  parser.add_argument(\"--multi-node\", default=False, action=\"store_true\")\n",
    "  parser.add_argument(\n",
    "      \"--single-node\", dest=\"multi-node\", action=\"store_false\"\n",
    "  )\n",
    "\n",
    "  parser.add_argument(\"--hptune\", default=False, action=\"store_true\")\n",
    "  parser.add_argument(\"--non-hptune\", dest=\"hptune\", action=\"store_false\")\n",
    "\n",
    "  args = parser.parse_args()\n",
    "  logging.info(\"Tensorflow version %s\", tf.__version__)\n",
    "\n",
    "  timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "  print(f\"timestamp: {timestamp}\")\n",
    "\n",
    "  log_dir = os.environ[\"AIP_TENSORBOARD_LOG_DIR\"]\n",
    "  print(f\" using (autogenerated) tb log dir: {log_dir}\")\n",
    "\n",
    "  checkpoint_dir = f\"{args.gcs_workdir}/checkpoints/{timestamp}/checkpoints\"\n",
    "  if args.hptune:  # add the trial id to the dir path\n",
    "    trial_id = os.environ.get(\"CLOUD_ML_TRIAL_ID\")\n",
    "    checkpoint_dir = f\"{checkpoint_dir}/{trial_id}\"\n",
    "  print(f\"checkpoint dir: {checkpoint_dir}\")\n",
    "\n",
    "  if args.copy_data:\n",
    "    # copy and unzip the dataset to the local file system\n",
    "    local_dir = \".\"\n",
    "    copy_data(args.input_data, local_dir)\n",
    "    data_dir = f\"{local_dir}/model_data/training_data\"\n",
    "    print(f\"training data dir: {data_dir}\")\n",
    "\n",
    "  # define and compile the model\n",
    "  print(\"creating the model..\")\n",
    "  if args.multi_node:\n",
    "    print(\"using MultiWorkerMirroredStrategy\")\n",
    "    strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
    "  else:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "  print(\"Number of devices: {}\".format(strategy.num_replicas_in_sync))\n",
    "\n",
    "  image_size = (int(args.image_height), int(args.image_width))\n",
    "  print(f'using image size: {image_size}')\n",
    "  (training_set, validation_set, _, _) = generate_camelyon_datasets(args.batch_size)\n",
    "\n",
    "\n",
    "  if strategy.num_replicas_in_sync > 1:\n",
    "    print(\"Using mirrored strategy.\")\n",
    "    with strategy.scope():\n",
    "      model = get_compiled_model(args.lr, int(args.image_height), int(args.image_width))\n",
    "  else:\n",
    "    model = get_compiled_model(args.lr, int(args.image_height), int(args.image_width))\n",
    "\n",
    "  model.summary()\n",
    "\n",
    "  # define callbacks\n",
    "  (tensorboard_callback, model_checkpoint_callback) = define_callbacks(\n",
    "      log_dir, checkpoint_dir\n",
    "  )\n",
    "\n",
    "  # train the model\n",
    "  print(f\"training the model with lr {args.lr}\")\n",
    "  model.fit(\n",
    "      training_set,\n",
    "      epochs=args.epochs,\n",
    "      callbacks=[tensorboard_callback, model_checkpoint_callback],\n",
    "      validation_data=validation_set,\n",
    "  )\n",
    "    \n",
    "  ## fine-tuning for patchcamelyon\n",
    "  print(\"Now fine-tuning the PatchCamelyon model\")\n",
    "  fine_tuning_epochs = 5\n",
    "  for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
    "  model.fit(training_set, epochs=fine_tuning_epochs, callbacks=[tensorboard_callback,\n",
    "            model_checkpoint_callback], validation_data=validation_set)    \n",
    "\n",
    "  print(\"saving the model to GCS\")\n",
    "  if args.hptune:\n",
    "    model_path_gcs = f\"{args.gcs_model_savedir}/{trial_id}\"\n",
    "  else:\n",
    "    if args.gcs_model_savedir == \"AIP_MODEL_DIR\" and os.getenv(\"AIP_MODEL_DIR\"):\n",
    "      model_path_gcs = os.getenv(\"AIP_MODEL_DIR\")\n",
    "    else:\n",
    "      model_path_gcs = args.gcs_model_savedir\n",
    "\n",
    "  print(f\"GCS saved model path: {model_path_gcs}\")\n",
    "  model.save(model_path_gcs)\n",
    "\n",
    "  # get some metrics info\n",
    "  print(f\"model history: {model.history.history}\")\n",
    "  val_accuracy = (model.history.history[\"val_accuracy\"])[-1]\n",
    "  val_loss = (model.history.history[\"val_loss\"])[-1]\n",
    "\n",
    "  (ma, mp, mr, all_preds, all_labels) = generate_metrics(\n",
    "      validation_set, model\n",
    "  )\n",
    "\n",
    "  # write out metrics info for 'eval' component\n",
    "  metrics_info = {\n",
    "      \"val_accuracy\": val_accuracy,\n",
    "      \"val_loss\": val_loss,\n",
    "      \"auc\": f\"{ma.result().numpy()}\",\n",
    "      \"precision\": f\"{ma.result().numpy()}\",\n",
    "      \"recall\": f\"{mr.result().numpy()}\",\n",
    "      \"all_labels\": f\"{all_labels}\",\n",
    "      \"all_preds\": f\"{all_preds}\",\n",
    "      \"num_classes\": len(LABELS),\n",
    "  }\n",
    "  print(f\"AUC: {ma.result().numpy()}\")\n",
    "  print(f\"Precision: {mp.result().numpy()}\")\n",
    "  print(f\"Recall: {mr.result().numpy()}\")\n",
    "\n",
    "  metrics_info_str = json.dumps(metrics_info)\n",
    "  print(f\"metrics info json string: {metrics_info_str}\")\n",
    "\n",
    "  Path(args.gcs_metrics_path).mkdir(parents=True, exist_ok=True)\n",
    "  metrics_info_file = f\"{args.gcs_metrics_path}/metrics.json\"\n",
    "\n",
    "  print(f\"writing metrics: {metrics_info_str} to {metrics_info_file}\")\n",
    "  with open(metrics_info_file, \"w\") as f:\n",
    "    f.write(metrics_info_str)\n",
    "\n",
    "  hpt = hypertune.HyperTune()\n",
    "  hpt.report_hyperparameter_tuning_metric(\n",
    "      hyperparameter_metric_tag=\"accuracy\",\n",
    "      metric_value=val_accuracy,\n",
    "      global_step=args.epochs,\n",
    "  )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c89cdd97bf11"
   },
   "source": [
    "Set some variables that we'll use to configure the Vertex AI SDK calls. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6b630237786e"
   },
   "source": [
    "We'll use GPUs for training, and CPUs for serving.  The images below need to be consistent with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8f85adc57b88"
   },
   "outputs": [],
   "source": [
    "TRAIN_IMAGE = \"us-docker.pkg.dev/vertex-ai/training/tf-gpu.2-6:latest\"\n",
    "DEPLOY_IMAGE = \"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-6:latest\"\n",
    "# alternately, to serve the model with GPUs: us-docker.pkg.dev/vertex-ai/prediction/tf2-gpu.2-6:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "28fd667c4570"
   },
   "outputs": [],
   "source": [
    "ts = int(time.time())\n",
    "\n",
    "MODEL_DISPLAY_NAME = f\"{USER}-pcam{NB_NUM}-{ts}\"\n",
    "EPOCHS = (\n",
    "    2  # set this to 3 or 4 for greater accuracy, or reduce to 1 for quicker training\n",
    ")\n",
    "GCS_WORKDIR = f\"gs://{BUCKET_NAME}/{MODEL_DISPLAY_NAME}\"\n",
    "\n",
    "# GCS_MODEL_SAVEDIR = f'{GCS_WORKDIR}/{ts}'\n",
    "GCS_MODEL_SAVEDIR = \"AIP_MODEL_DIR\"  # indicate to use Vertex AI-generated dir in order to automate the model upload\n",
    "\n",
    "GCS_METRICS_PATH = f\"/gcs/{BUCKET_NAME}/{MODEL_DISPLAY_NAME}/metrics/{ts}\"\n",
    "print(f\"MODEL_DISPLAY_NAME: {MODEL_DISPLAY_NAME}\")\n",
    "print(f\"model savedir: {GCS_MODEL_SAVEDIR}, GCS_METRICS_PATH: {GCS_METRICS_PATH}\")\n",
    "\n",
    "CMDARGS = [\n",
    "    \"--epochs\",\n",
    "    str(EPOCHS),\n",
    "    \"--gcs-workdir\",\n",
    "    GCS_WORKDIR,\n",
    "    \"--gcs-model-savedir\",\n",
    "    GCS_MODEL_SAVEDIR,\n",
    "    \"--gcs-metrics-path\",\n",
    "    GCS_METRICS_PATH,\n",
    "    \"--image-height\",\n",
    "    str(IMAGE_HEIGHT),\n",
    "    \"--image-width\",\n",
    "    str(IMAGE_WIDTH),\n",
    "    \"--ml-task\",\n",
    "    \"patchcamelyon\",\n",
    "]\n",
    "print(CMDARGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6abb345f35de"
   },
   "source": [
    "Here we'll indicate the machine type and accelerator type and number for the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d4ffa3f9d2e3"
   },
   "outputs": [],
   "source": [
    "TRAIN_GPU, TRAIN_NGPU = (aip.AcceleratorType.NVIDIA_TESLA_T4, 2)\n",
    "TRAIN_COMPUTE = \"n1-highmem-8\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01eaa30138e9"
   },
   "source": [
    "### Create and run a training job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "73f141d275ab"
   },
   "source": [
    "Now, we're ready to define and run a training job on Vertex AI. \n",
    "\n",
    "#### Log information about the training job to the Vertex Experiments API\n",
    "\n",
    "Before submitting the job, we'll log some information about this training job to the Experiment we created above, starting a new 'run' for the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a4562f906e70"
   },
   "outputs": [],
   "source": [
    "aiplatform.start_run(\"train-run-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3871b872586d"
   },
   "source": [
    "Gather info about the job parameters and log that to the Experiments run info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "725ce1a80590"
   },
   "outputs": [],
   "source": [
    "args_dict = {CMDARGS[i]: CMDARGS[i + 1] for i in range(0, len(CMDARGS), 2)}\n",
    "print(args_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dcf28adb15e9"
   },
   "outputs": [],
   "source": [
    "# you can commment out the addition of the TENSORBOARD_INSTANCE if that value is not set\n",
    "HYPERPARAMS = {\n",
    "    \"model_display_name\": MODEL_DISPLAY_NAME,\n",
    "    \"tensorboard_instance\": TENSORBOARD_INSTANCE,\n",
    "}\n",
    "HYPERPARAMS = {**HYPERPARAMS, **args_dict}\n",
    "print(HYPERPARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "feb9d384636c"
   },
   "outputs": [],
   "source": [
    "aiplatform.log_params(HYPERPARAMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c531d28b5ccd"
   },
   "source": [
    "Just for fun, we can see what we have logged about the Experiments run so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3f4becbe95b3"
   },
   "outputs": [],
   "source": [
    "dataframe = aiplatform.get_experiment_df(experiment=EXPERIMENT_NAME)\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23e7c3c9855e"
   },
   "source": [
    "#### Define and submit the training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5f2e73503024"
   },
   "outputs": [],
   "source": [
    "job = aiplatform.CustomTrainingJob(\n",
    "    display_name=MODEL_DISPLAY_NAME,\n",
    "    script_path=\"pcamtask.py\",\n",
    "    container_uri=TRAIN_IMAGE,\n",
    "    requirements=[\"cloudml-hypertune\"],\n",
    "    model_serving_container_image_uri=DEPLOY_IMAGE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1e5681cdf856"
   },
   "source": [
    "The alternate version below uses a 'package', not a script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "505fbf158c47"
   },
   "outputs": [],
   "source": [
    "PYTHON_PACKAGE_GCS_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2bb4e0a53991"
   },
   "outputs": [],
   "source": [
    "# job = aiplatform.CustomPythonPackageTrainingJob(\n",
    "#    display_name=MODEL_DISPLAY_NAME,\n",
    "#    python_package_gcs_uri=PYTHON_PACKAGE_GCS_URI,\n",
    "#    python_module_name='trainer.task',\n",
    "#    container_uri=TRAIN_IMAGE,\n",
    "#    model_serving_container_image_uri=DEPLOY_IMAGE,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d379be62c09d"
   },
   "source": [
    "If you didn't set up a Managed TensorBoard instance, you can comment out the `tensorboard` arg below before you run the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b32379a0420d"
   },
   "outputs": [],
   "source": [
    "# confirm the service account used for training\n",
    "TRAINING_SA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "34f82662c64f"
   },
   "outputs": [],
   "source": [
    "model = job.run(\n",
    "    model_display_name=MODEL_DISPLAY_NAME,\n",
    "    args=CMDARGS,\n",
    "    replica_count=1,\n",
    "    machine_type=TRAIN_COMPUTE,\n",
    "    accelerator_type=TRAIN_GPU.name,\n",
    "    accelerator_count=TRAIN_NGPU,\n",
    "    tensorboard=TENSORBOARD_INSTANCE,\n",
    "    service_account=TRAINING_SA,\n",
    "    sync=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "18751f45642c"
   },
   "source": [
    "You can click on the 'custom job' link generated when you submit the training job, to view information about the job in the Cloud Console. From that page you can click on the job logs to see output of the training job as it runs.\n",
    "\n",
    "The `sync=False` arg to the training job means that the call is non-blocking; it will return even though training is still running. (However, you'll see it generate some output to the current notebook cell while it runs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"#---you will need the following if your notebook loses context.\")\n",
    "print(f'GCS_METRICS_PATH = \"{GCS_METRICS_PATH}\"')\n",
    "print(f'MODEL_DISPLAY_NAME = \"{MODEL_DISPLAY_NAME}\"')\n",
    "print(f'EXPERIMENT_NAME = \"{EXPERIMENT_NAME}\"')\n",
    "print(f'aiplatform.init(experiment=\"{EXPERIMENT_NAME}\")')\n",
    "print(\"#----------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Wait until training has finished to proceed with the rest of this example**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After training finishes\n",
    "\n",
    "**Wait until training has completed** to run this section.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you have lost notebook context during training\n",
    "\n",
    "After training finishes: If you've lost notebook context during training, do two things:\n",
    "\n",
    "1) first **re-run Section 1.2: Config and setup**.\n",
    "2) Then, copy and run the output from the cell above (the output that includes: `you will need the following...`), to re-set some of the training config before proceeding. Note that you're not only setting some variables, but re-setting your Experiment context via the Vertex AI SDK in order to log some more information to it. Double check that you're only copying and pasting the output of the print statements.\n",
    "\n",
    "If you have any issues running the following sections, double check that you've completed the steps above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e70a86781c99"
   },
   "source": [
    "## Retrieve and save the training metrics to the Experiments `run` info\n",
    "\n",
    "**Wait until training has completed** to run this section.\n",
    "\n",
    "If you have trouble, you can skip this part of the example, which is just grabbing and logging some information about the training metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ca68d294b25"
   },
   "outputs": [],
   "source": [
    "# Ensure that the GCS_METRICS_PATH var is set correctly.\n",
    "GCS_METRICS_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eec0572cfe14"
   },
   "source": [
    "Grab the file with metrics info that was generated as part of the model training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ac0d58d2b9a"
   },
   "outputs": [],
   "source": [
    "metrics_file = f\"{GCS_METRICS_PATH}/metrics.json\".replace(\"/gcs/\", \"gs://\")\n",
    "metrics_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4c8691f1f084"
   },
   "source": [
    "Parse the metrics info.  For the purposes of experiment logging, we won't include the array info generated for the confusion metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "488cb136fd51"
   },
   "outputs": [],
   "source": [
    "!gsutil cat $metrics_file > temp_metrics.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"temp_metrics.json\") as fp:\n",
    "    metrics = json.load(fp)\n",
    "    _ = metrics.pop(\"all_labels\")\n",
    "    _ = metrics.pop(\"all_preds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c254a97e5340"
   },
   "outputs": [],
   "source": [
    "metrics = {k: float(v) for k, v in metrics.items()}\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "951443ac3389"
   },
   "source": [
    "Ensure we're using the correct 'run' context within the Experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "78b7ae2389c8"
   },
   "outputs": [],
   "source": [
    "aiplatform.start_run(\"train-run-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "df2d0c0fd859"
   },
   "source": [
    "Log the metrics info to the run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "74cd4e54823a"
   },
   "outputs": [],
   "source": [
    "aiplatform.log_metrics(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "effe4bb80e63"
   },
   "source": [
    "We can take a look at the info we've logged so far to the Experiment run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cb6ab8058465"
   },
   "outputs": [],
   "source": [
    "dataframe = aiplatform.get_experiment_df(experiment=EXPERIMENT_NAME)\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8d21796ea1c1"
   },
   "source": [
    "## Deploy the trained model to an endpoint\n",
    "\n",
    "**Wait until training has completed** to run this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0dbdb6ae5c47"
   },
   "outputs": [],
   "source": [
    "TRAFFIC_SPLIT = {\"0\": 100}\n",
    "\n",
    "MIN_NODES = 1\n",
    "MAX_NODES = 1\n",
    "DEPLOY_COMPUTE = \"n1-standard-4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "320bbdaf07f8"
   },
   "outputs": [],
   "source": [
    "# check whether your model variable is set\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63fda49e0f44",
    "tags": []
   },
   "source": [
    "### If your `model` variable is no longer set\n",
    "\n",
    "If you've lost notebook context and your `model` variable is no longer set, you can reconstitute it before running the `deploy` method below.  The code below attempts to do this automatically (uncomment before running), but you can also re-set the model variable via its model ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## uncomment the code in this cell to attempt to get the model object automatically.\n",
    "# modellist = aiplatform.Model.list()\n",
    "# for model in modellist:\n",
    "#     if f'{USER}-pcam{NB_NUM}' in model.display_name:\n",
    "#         print(f'found a match for USER {USER}: {model}, {model.display_name}')\n",
    "#         break\n",
    "\n",
    "# print(f'model is: {model}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the above didn't work, then you can recreate the model object via its ID.\n",
    "To find the model ID, one easy way is to visit the list of models in the Cloud Console: https://console.cloud.google.com/vertex-ai/models.  The name of the model should include your username and the 'pcam' string.  Copy the listed ID for that model. Then, edit and run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ba01a14da54a"
   },
   "outputs": [],
   "source": [
    "# You can use this code to re-set your model variable if you've lost notebook context after training.\n",
    "# model = aiplatform.Model('xxxxxxxxxxxxxxxxxxx')  # <-- CHANGE this to your model ID\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that MODEL_DISPLAY_NAME is set to the value used for the training request.\n",
    "MODEL_DISPLAY_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dc75ce098ceb"
   },
   "outputs": [],
   "source": [
    "# make sure the 'model' var and 'MODEL_DISPLAY_NAME' are set before running this cell.\n",
    "endpoint = model.deploy(\n",
    "    deployed_model_display_name=MODEL_DISPLAY_NAME,\n",
    "    traffic_split=TRAFFIC_SPLIT,\n",
    "    machine_type=DEPLOY_COMPUTE,\n",
    "    # accelerator_type=DEPLOY_COMPUTE.name,\n",
    "    accelerator_count=0,\n",
    "    min_replica_count=MIN_NODES,\n",
    "    max_replica_count=MAX_NODES,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7522342f4e22"
   },
   "source": [
    "## Prediction\n",
    "\n",
    "Now, you can send prediction requests to the deployed model at the endpoint you created.\n",
    "\n",
    "Make sure that the `endpoint` var is set.  If you've lost notebook context, you can reconstitute it by specifying the Endpoint ID as shown below. To find the endpoint ID, one easy way is to visit the list of endpoints in the Cloud Console: https://console.cloud.google.com/vertex-ai/endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7639e34a0cf2"
   },
   "outputs": [],
   "source": [
    "# endpoint = aiplatform.Endpoint('xxxxxxxxxxxxxxxxxxx')\n",
    "endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "17450a7ab203"
   },
   "outputs": [],
   "source": [
    "LABELS = [\"non_metastatic\", \"metastatic\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4afe028cd6be"
   },
   "source": [
    "Copy a test image.  This one has label 0 (non_metastatic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c3a42e581030"
   },
   "outputs": [],
   "source": [
    "!gsutil cp gs://fc-b60eeef5-8162-47a8-8114-d8dd82b65653/data/patch_camelyon/label_0/download.png ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3d690da41879"
   },
   "source": [
    "Resize the image, and render it as a sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7a3e7df5b45c"
   },
   "outputs": [],
   "source": [
    "image_file = \"./download.png\"\n",
    "display(IPython.display.Image(image_file))\n",
    "\n",
    "img1 = Image.open(image_file)\n",
    "img2 = img1.resize((92, 92), resample=PIL.Image.NEAREST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7380586d79ec"
   },
   "outputs": [],
   "source": [
    "image_data = np.array(img2)\n",
    "img_array = np.float32(image_data)[:, :, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "55d2a92f7efe"
   },
   "outputs": [],
   "source": [
    "img_array2 = img_array.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b55bc17fe2bc"
   },
   "source": [
    "Send the image data to the Endpoint where your model was deployed, for online prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2b286008dd2a"
   },
   "outputs": [],
   "source": [
    "predictions = endpoint.predict(instances=[img_array2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05f7c7d352cd"
   },
   "source": [
    "View the prediction results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "71fd2ca620c6"
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9f3f908839fe"
   },
   "outputs": [],
   "source": [
    "image_predictions = predictions.predictions[0]\n",
    "image_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3af58329ef2"
   },
   "source": [
    "Check whether the image prediction matches its label (that is, its actual class):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "084f61ccc5ae"
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"image is predicted to be: {LABELS[image_predictions.index(max(image_predictions))]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53c100e08af8"
   },
   "source": [
    "## Cleanup\n",
    "\n",
    "Delete the endpoint and model that you created.  You'll need to first undeploy the model from the endpoint before you can delete either.\n",
    "\n",
    "The training instances are automatically torn down after the job completes. \n",
    "\n",
    "Delete the endpoint and model that you created.  The training instances and pipeline step instances are automatically torn down after the job completes. \n",
    "\n",
    "If the GCS bucket that you used is not set to automatically delete old files, then you can clean up your GCS bucket as well.  An easy way to do this is via the [Cloud Console UI](https://pantheon.corp.google.com/storage/browser)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d3215d92a195"
   },
   "outputs": [],
   "source": [
    "# print(f\"Endpoint: {endpoint}\\n{endpoint.list_models()}\")\n",
    "# print(f\"Model: {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f076d9f5f788"
   },
   "outputs": [],
   "source": [
    "endpoint.undeploy_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9da37d44155f"
   },
   "outputs": [],
   "source": [
    "# Delete the model\n",
    "# if you've lost notebook context, you can first reconstruct the model object as follows.\n",
    "# Edit the model ID for your model.\n",
    "# model = aiplatform.Model('xxxxxxxxxxxxxxxxxxx')  # <-- CHANGE THIS\n",
    "model.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1c97ffec5681"
   },
   "outputs": [],
   "source": [
    "# Delete the endpoint\n",
    "# if you've lost notebook context, you can first reconstruct the Endpoint object as follows.\n",
    "# Edit the ID for your endpoint.\n",
    "# endpoint = aiplatform.Endpoint('xxxxxxxxxxxxxxxxxxx')  # <-- CHANGE THIS\n",
    "endpoint.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6362bc153bfb"
   },
   "outputs": [],
   "source": [
    "# Delete the Experiment\n",
    "# This code requires google-cloud-aiplatform >=1.8\n",
    "c = aiplatform.metadata._Context(EXPERIMENT_NAME)\n",
    "c.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ecb129b8402b"
   },
   "source": [
    "--------------------------------\n",
    "Copyright 2021 Verily Life Sciences LLC\n",
    "\n",
    "Use of this source code is governed by a BSD-style  \n",
    "license that can be found in the LICENSE file or at  \n",
    "https://developers.google.com/open-source/licenses/bsd"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "02_1_vertex_ai_pcam.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-7.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-7:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
