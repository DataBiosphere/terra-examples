{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03b36b77f334"
   },
   "source": [
    "# 'PatchCamelyon' image classification using Keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dc13b365348f"
   },
   "source": [
    "### About the ML task and dataset\n",
    "\n",
    "This notebook shows an example of training an _image classification_ [Keras](https://keras.io/) model.\n",
    "\n",
    "The [PatchCamelyon benchmark](https://www.tensorflow.org/datasets/catalog/patch_camelyon) consists of 327,680 color images (96 x 96px) extracted from histopathologic scans of lymph node sections. Each image is annotated with a\n",
    "binary label indicating presence of metastatic tissue. \n",
    "\n",
    "The model uses one of Keras' prebuilt model architectures, [Xception](https://keras.io/api/applications/xception/). The training does [_transfer learning_](https://en.wikipedia.org/wiki/Transfer_learning) , bootstrapping from model weights trained on the ['imagenet'](https://en.wikipedia.org/wiki/ImageNet) dataset, then runs a [fine-tuning](https://d2l.ai/chapter_computer-vision/fine-tuning.html) stage.\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/tfds-data/visualization/fig/patch_camelyon-2.0.0.png\" width=\"60%\">\n",
    "\n",
    "This notebook **works best with GPU(s)** -- it runs fine using only CPUs, but training takes a longer time. Given the size of the dataset and model architecture, this example requires a 2-core notebook VM, and the notebook should use an attached GPU to run in a reasonable time frame.  On CWB Terra, you can use the default GATK image customized to use **2 CPUs and 1 GPU**.\n",
    "\n",
    "You can use this notebook as a template for experimenting with image classification on your own image data.\n",
    "<!-- (**TBD**: more on how to do this.) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35ca3da3e803"
   },
   "source": [
    "## Do some imports and set some variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "53e4b75dc3f8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2b02d5691f1a"
   },
   "source": [
    "Get your workspace GCS bucket using Workspace Data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "823b4128c125"
   },
   "outputs": [],
   "source": [
    "if (\n",
    "    \"GOOGLE_PROJECT\" in os.environ\n",
    "):  # This env var is set when running in a Terra workspace\n",
    "    from firecloud import api as fapi\n",
    "\n",
    "    WORKSPACE_NAME = os.environ[\"WORKSPACE_NAME\"]\n",
    "    WORKSPACE_NAMESPACE = os.environ[\"WORKSPACE_NAMESPACE\"]\n",
    "    WORKSPACE_BUCKET = os.environ[\"WORKSPACE_BUCKET\"]\n",
    "else:\n",
    "    print(\"Not running on Terra: you will need to set your GCP bucket manually.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "826a37498e5a"
   },
   "outputs": [],
   "source": [
    "BUCKET = WORKSPACE_BUCKET\n",
    "print(BUCKET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9eaddb8f7bf5"
   },
   "outputs": [],
   "source": [
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "print(TIMESTAMP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2e6786be03d9"
   },
   "source": [
    "## Create the tissue datasets\n",
    "\n",
    "This process will take a while. We'll download to the persistent disk, so that you only need to do the download once (per PD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0d345d66a628"
   },
   "outputs": [],
   "source": [
    "# load the input data from tensorflow_datasets\n",
    "ds, ds_info = tfds.load(\n",
    "    \"patch_camelyon\",\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    "    data_dir=\"/home/jupyter/tensorflow_datasets\",\n",
    ")\n",
    "\n",
    "# get the train, validation and test datasets\n",
    "train_data = ds[\"train\"]\n",
    "valid_data = ds[\"validation\"]\n",
    "test_data = ds[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "23e42d082046"
   },
   "outputs": [],
   "source": [
    "print(ds_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bf3a2eaa2534"
   },
   "outputs": [],
   "source": [
    "# shuffle the train_data\n",
    "buffer_size = 1000\n",
    "train_data = train_data.shuffle(buffer_size)\n",
    "\n",
    "# batch and prefetch\n",
    "batch_size = 32\n",
    "train_data = train_data.batch(batch_size).prefetch(1)\n",
    "valid_data = valid_data.batch(batch_size).prefetch(1)\n",
    "test_data = test_data.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddeb1408a68a"
   },
   "source": [
    "We can view a few of the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b660c3c3af92"
   },
   "outputs": [],
   "source": [
    "for images, labels in train_data.take(3):\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    first_image = images[0]\n",
    "    plt.imshow(first_image.numpy().astype(\"int32\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "769a2a624298"
   },
   "source": [
    "## Define a Keras image classification model\n",
    "\n",
    "In this section, we'll define the Keras model that we'll use for training. We'll use [transfer learning](https://en.wikipedia.org/wiki/Transfer_learning) for this example, starting with a model— the [Xception](https://keras.io/api/applications/xception/) convolutional neural network architecture — that has been trained on [ImageNet](https://www.image-net.org/) data, and adding some additional layers to that model. We'll 'freeze' the Xception base model, so that its weights don't change during training; only the weights of our new layers will change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4d8c21c56efc"
   },
   "outputs": [],
   "source": [
    "def get_compiled_model():\n",
    "    base_model = keras.applications.Xception(\n",
    "        weights=\"imagenet\", input_shape=(96, 96, 3), include_top=False\n",
    "    )\n",
    "\n",
    "    base_model.trainable = False\n",
    "\n",
    "    inputs = keras.Input(shape=(96, 96, 3))\n",
    "\n",
    "    x = layers.Rescaling(1.0 / 255)(inputs)\n",
    "    x = base_model(x, training=False)\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = keras.layers.Dropout(0.2)(x)\n",
    "    outputs = keras.layers.Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "    # model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "        loss=loss,\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return (base_model, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c62890e73b13"
   },
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(\"Number of devices: {}\".format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ad9e7e444f19"
   },
   "outputs": [],
   "source": [
    "if strategy.num_replicas_in_sync > 1:\n",
    "    print(\"Using mirrored strategy.\")\n",
    "    with strategy.scope():\n",
    "        base_model, model = get_compiled_model()\n",
    "else:\n",
    "    base_model, model = get_compiled_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "09ac0f2d86ca"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d04c4d48e311"
   },
   "source": [
    "Define some training 'callbacks'. One logs in a format used by [TensorBoard](https://www.tensorflow.org/tensorboard).  The other sets up model checkpointing. If training is interrupted for some reason, we can reconstitute the last-saved model from the checkpoint directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "44e3088550e4"
   },
   "outputs": [],
   "source": [
    "# LOG_DIR = f'./logs/{TIMESTAMP}'\n",
    "LOG_DIR = f\"{BUCKET}/logs/pc/{TIMESTAMP}\"\n",
    "\n",
    "print(LOG_DIR)\n",
    "CHECKPOINT_DIR = f\"./checkpoints/{TIMESTAMP}/checkpoints\"\n",
    "print(CHECKPOINT_DIR)\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR, update_freq=300)\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=CHECKPOINT_DIR,\n",
    "    #     save_weights_only=True,\n",
    "    monitor=\"val_accuracy\",\n",
    "    mode=\"max\",\n",
    "    save_freq=\"epoch\"\n",
    "    #     save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fd755c8c5eb2"
   },
   "source": [
    "## Train the model\n",
    "\n",
    "Train the model, using transfer learning, for a few epochs. The base model weights are 'frozen' for this training run, and won't be updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0c9b53e2ed9b"
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_data,\n",
    "    epochs=4,\n",
    "    callbacks=[tensorboard_callback, model_checkpoint_callback],\n",
    "    validation_data=valid_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "425647aed9f7"
   },
   "source": [
    "## Fine-tune the trained model\n",
    "\n",
    "Next, we'll do some model [fine-tuning](https://d2l.ai/chapter_computer-vision/fine-tuning.html), unfreezing the rest of the model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "65a63e17e733"
   },
   "outputs": [],
   "source": [
    "# 'Unfreeze' the rest of the model\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2bee1cec69a0"
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_data,\n",
    "    epochs=3,\n",
    "    callbacks=[tensorboard_callback, model_checkpoint_callback],\n",
    "    validation_data=valid_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "deaf2fd2f2d8"
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "432bcdd45756"
   },
   "source": [
    "### Save the trained model\n",
    "\n",
    "#### Save to the local file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cb4089b50475"
   },
   "outputs": [],
   "source": [
    "model_path = f\"./saved_model/{TIMESTAMP}\"\n",
    "print(f\"model path: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "02ab9d59c258"
   },
   "outputs": [],
   "source": [
    "# save the model\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31189e9814d0"
   },
   "source": [
    "#### Save the model to GCS\n",
    "\n",
    "Alternately, you can save the model to a GCS bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4a24ab9728a0"
   },
   "outputs": [],
   "source": [
    "model_path_gcs = f\"{BUCKET}/pcam/saved_models/{TIMESTAMP}\"\n",
    "print(f\"GCS model path: {model_path_gcs}\")\n",
    "model.save(model_path_gcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1757f6f9dba4"
   },
   "source": [
    "#### Load a saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "25bbbdd63f3e"
   },
   "outputs": [],
   "source": [
    "# later, you can load and use the saved model by providing a local or GCS path, e.g.:\n",
    "\n",
    "model2 = keras.models.load_model(model_path_gcs)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3c5425e928aa"
   },
   "source": [
    "## Model prediction\n",
    "\n",
    "We can now use the trained model for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ee8a961b03dc"
   },
   "outputs": [],
   "source": [
    "LABELS = [\"non_metastic\", \"metastic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "93c19209d1db"
   },
   "outputs": [],
   "source": [
    "for images, labels in test_data.take(1):\n",
    "    print(f\"labels: {labels}\")\n",
    "    predictions = model.predict(images)\n",
    "    print(f\"predictions: {predictions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c846f05035c3"
   },
   "outputs": [],
   "source": [
    "for i, p in enumerate(predictions):\n",
    "    idx = list(p).index(max(p))\n",
    "    if i < 4:\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        plt.imshow(images[i].numpy().astype(\"int32\"))\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(\n",
    "            f\"image is predicted to be: {LABELS[idx]}, with label {LABELS[labels[i]]}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f041f69df50a"
   },
   "source": [
    "## Model metrics\n",
    "\n",
    "Now let's derive some model metrics.  We'll get the predictions from the validation set, and use those for building a [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix), as well as [precision, recall](https://en.wikipedia.org/wiki/Precision_and_recall), and [AUC](https://en.wikipedia.org/wiki/AUC) metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "406065cce01f"
   },
   "outputs": [],
   "source": [
    "ma = tf.keras.metrics.AUC()\n",
    "mp = tf.keras.metrics.Precision()\n",
    "mr = tf.keras.metrics.Recall()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "for images, labels in valid_data.take(len(valid_data)):\n",
    "    predictions = model.predict(images)\n",
    "    y_preds = np.argsort(predictions, axis=1)[:, -1:]\n",
    "    all_preds += list(y_preds.flatten())\n",
    "    all_labels += list(labels.numpy())\n",
    "    onehot_labels = tf.keras.utils.to_categorical(labels, num_classes=len(LABELS))\n",
    "    ma.update_state(onehot_labels, predictions)\n",
    "    mp.update_state(onehot_labels, predictions)\n",
    "    mr.update_state(onehot_labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2e8ae9f644ab"
   },
   "source": [
    "We'll show two different ways to create a confusion matrix -- `tf.math.confusion_matrix` and `sklearn.metrics.confusion_matrix`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a7cbd5f61e4c"
   },
   "outputs": [],
   "source": [
    "def show_confusion_matrix(cm, labels):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    sns.heatmap(cm, xticklabels=labels, yticklabels=labels, annot=True, fmt=\"g\")\n",
    "    plt.xlabel(\"Prediction\")\n",
    "    plt.ylabel(\"Label\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "cm = tf.math.confusion_matrix(all_labels, all_preds, num_classes=len(LABELS))\n",
    "# print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "61935c22702e"
   },
   "outputs": [],
   "source": [
    "show_confusion_matrix(cm, LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56f476a40215"
   },
   "source": [
    "We can optionally calculate 'percentage' information from the confusion matrix and plot that instead of the raw numbers, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b3bd85593bc1"
   },
   "outputs": [],
   "source": [
    "scm = confusion_matrix(all_labels, all_preds)\n",
    "scm = scm.astype(\"float\") / scm.sum(axis=1)[:, np.newaxis]\n",
    "disp = ConfusionMatrixDisplay(scm, display_labels=LABELS)\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "disp.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8d79256834df"
   },
   "outputs": [],
   "source": [
    "print(f\"AUC: {ma.result().numpy()}\")\n",
    "print(f\"Precision: {mp.result().numpy()}\")\n",
    "print(f\"Recall: {mr.result().numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ffb2608bb6a"
   },
   "source": [
    "--------------------------------\n",
    "Copyright 2021 Verily Life Sciences LLC\n",
    "\n",
    "Use of this source code is governed by a BSD-style  \n",
    "license that can be found in the LICENSE file or at  \n",
    "https://developers.google.com/open-source/licenses/bsd"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "01_keras_pcam.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-7.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-7:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
