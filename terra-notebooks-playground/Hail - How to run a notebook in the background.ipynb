{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run a Hail notebook in the background\n",
    "\n",
    "Terra users frequently use notebooks interactively to test [Hail](https://hail.is/) analyses on small portions of the genome. But running that same notebook over more data may take hours. For long running Hail jobs, if the browser loses its connection, users may not have all notebook cell outputs populated even though the notebook continues to run to completion.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>If you wish to capture all Hail notebook cell outputs</b>, use this notebook to run your long-running Hail notebook (or any other long-running notebook).<p>But also note that your analysis <a href=\"https://support.terra.bio/hc/en-us/articles/360029761352-Preventing-runaway-costs-with-notebook-auto-pause-#h_de5698f5-3c82-4763-aaaf-ea7df6a1869c\">must complete within 24 hours</a>.</p>\n",
    "</div>\n",
    "\n",
    "How to use this notebook:\n",
    "1. Copy this notebook to the workspace that contains the long-running notebook you wish to run in the background.\n",
    "1. Edit the filename in `NOTEBOOK_TO_RUN` to be the name of the notebook in this workspace you wish to run.\n",
    "1. Use menu `Cell -> Run All` to tell the kernel to run this notebook to completion.\n",
    "1. Close this tab and do other work. (note: when you close the tab, the outputs in *this* notebook will no longer be updated, and that is fine, because what we really want are the outputs in the Hail notebook.)\n",
    "1. When the Hail job is complete:\n",
    "    1. Your Hail cluster will pause (if you have no other notebooks open).\n",
    "    1. You will see a copy of your notebook in the notebooks tab with a date and timestamp suffix --> this is the output file.\n",
    "    1. You will also see the Hail log in `gs://<workspace bucket>/hail-logs/YYYYMMDD/hail*.log`\n",
    "\n",
    "If you check back, and you do not see the output notebook, the Hail job is still running. To confirm this, first notice whether your Cloud analysis environment is still running. If it is, from the terminal run `yarn application -list` to see that a spark context is still processing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat\n",
    "from nbconvert.preprocessors import CellExecutionError\n",
    "from nbconvert.preprocessors import ExecutePreprocessor\n",
    "\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Change the cell below</b> to hold the name of the notebook in this workspace that you wish to run in the background. There is no need to modify any of the other cells.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------[ CHANGE THIS TO BE THE NAME OF THE NOTEBOOK YOU WISH TO RUN ]-----------\n",
    "NOTEBOOK_TO_RUN = 'your_notebook.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programmatically set output paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formulate a new filename for the output notebook so that it includes a date and timestamp for when it was executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMP_FILE_SUFFIX = time.strftime('_%Y%m%d_%H%M%S.ipynb')\n",
    "OUTPUT_NOTEBOOK = NOTEBOOK_TO_RUN.replace('.ipynb', TIMESTAMP_FILE_SUFFIX)\n",
    "\n",
    "print(f'Executed notebook will be written to filename \"{OUTPUT_NOTEBOOK}\" on the local disk and the workspace bucket.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATESTAMP = time.strftime('%Y%m%d')\n",
    "HAIL_LOG_DIR_FOR_PROVENANCE = f'{os.getenv(\"WORKSPACE_BUCKET\")}/hail-logs/{DATESTAMP}/'\n",
    "\n",
    "print(f'Hail logs will be copied to {HAIL_LOG_DIR_FOR_PROVENANCE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the notebook and capture provenance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "The next cell will use <kbd>nbconvert</kbd> to run the notebook in the background until it completes (or yields an error) and will capture all notebook outputs as a separate notebook file.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See also https://nbconvert.readthedocs.io/en/latest/execute_api.html\n",
    "with open(NOTEBOOK_TO_RUN) as f_in:\n",
    "    nb = nbformat.read(f_in, as_version=4)\n",
    "    # Use a timeout of 24 hours, which is the same duration as the autopause threshold for active clusters.\n",
    "    ep = ExecutePreprocessor(timeout=(60 * 60 * 24), kernel_name='python3')\n",
    "    try:\n",
    "        out = ep.preprocess(nb, {'metadata': {'path': ''}})\n",
    "    except CellExecutionError:\n",
    "        out = None\n",
    "        msg = 'Error executing the notebook \"%s\".\\n\\n' % NOTEBOOK_TO_RUN\n",
    "        msg += 'See notebook \"%s\" for the traceback.' % OUTPUT_NOTEBOOK\n",
    "        print(msg)\n",
    "    finally:\n",
    "        with open(OUTPUT_NOTEBOOK, mode='w', encoding='utf-8') as f_out:\n",
    "            nbformat.write(nb, f_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    When notebook has finished execution, the next cell will use <kbd>gsutil</kbd> to copy it from the local disk to the workspace bucket.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s $OUTPUT_NOTEBOOK\n",
    "\n",
    "gsutil cp \"${1}\" ${WORKSPACE_BUCKET}/notebooks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    When notebook has finished execution, the next cell will use <kbd>gsutil</kbd> to copy all hail logs from the execution directory on the local disk to the workspace bucket.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s $HAIL_LOG_DIR_FOR_PROVENANCE\n",
    "\n",
    "gsutil -m cp hail*.log ${1}"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "r-cpu.3-6.m56",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/r-cpu.3-6:m56"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
